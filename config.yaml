app:
  name: "Past Life Predictor"
  version: "1.0.0"
  debug: true

models:
  local_llm:
    name: "llama2:7b"
    temperature: 0.3
    max_tokens: 512
  
  embeddings:
    model: "all-MiniLM-L6-v2"
    cache_dir: "./models/embeddings"
  
  cloud_llm:
    provider: "gemini"
    model: "gemini-1.5-flash"
    temperature: 0.7
    max_tokens: 1024

preprocessing:
  min_text_length: 10
  max_text_length: 1000
  remove_stopwords: true
  use_lemmatization: true

analysis:
  personality_traits: ["openness", "conscientiousness", "extraversion", "agreeableness", "neuroticism"]
  confidence_threshold: 0.6
  cultural_contexts: ["western", "eastern", "ancient", "medieval", "renaissance", "modern"]

api_keys:
  gemini: "your-gemini-api-key-here" # This will be overridden by the .env file